syntax = "proto3";

package tensorflow;

 mport "google/protobuf/any.proto";
 mport "tensorflow/core/fra work/graph.proto";
 mport "tensorflow/core/fra work/op_def.proto";
 mport "tensorflow/core/fra work/tensor_shape.proto";
 mport "tensorflow/core/fra work/types.proto";
 mport "tensorflow/core/protobuf/saved_object_graph.proto";
 mport "tensorflow/core/protobuf/saver.proto";
 mport "tensorflow/core/protobuf/struct.proto";

opt on cc_enable_arenas = true;
opt on java_outer_classna  = " taGraphProtos";
opt on java_mult ple_f les = true;
opt on java_package = "org.tensorflow.fra work";
opt on go_package = "g hub.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto";

// NOTE: T  protocol buffer  s evolv ng, and w ll go through rev s ons  n t 
// com ng months.
//
// Protocol buffer conta n ng t  follow ng wh ch are necessary to restart
// tra n ng, run  nference.   can be used to ser al ze/de-ser al ze  mory
// objects necessary for runn ng computat on  n a graph w n cross ng t 
// process boundary.   can be used for long term storage of graphs,
// cross-language execut on of graphs, etc.
//    ta nfoDef
//   GraphDef
//   SaverDef
//   Collect onDef
//   Tensor nfo
//   S gnatureDef
 ssage  taGraphDef {
  //  ta  nformat on regard ng t  graph to be exported.  To be used by users
  // of t  protocol buffer to encode  nformat on regard ng t  r  ta graph.
   ssage  ta nfoDef {
    // User spec f ed Vers on str ng. Can be t  na  of t  model and rev s on,
    // steps t  model has been tra ned to, etc.
    str ng  ta_graph_vers on = 1;

    // A copy of t  OpDefs used by t  producer of t  graph_def.
    // Descr pt ons and Ops not used  n graph_def are str pped out.
    OpL st str pped_op_l st = 2;

    // A ser al zed protobuf. Can be t  t   t   ta graph  s created, or
    // mod f ed, or na  of t  model.
    google.protobuf.Any any_ nfo = 3;

    // User suppl ed tag(s) on t   ta_graph and  ncluded graph_def.
    //
    //  taGraphDefs should be tagged w h t  r capab l  es or use-cases.
    // Examples: "tra n", "serve", "gpu", "tpu", etc.
    // T se tags enable loaders to access t   taGraph(s) appropr ate for a
    // spec f c use-case or runt   env ron nt.
    repeated str ng tags = 4;

    // T  __vers on__ str ng of t  tensorflow bu ld used to wr e t  graph.
    // T  w ll be populated by t  fra work, wh ch w ll overwr e any user
    // suppl ed value.
    str ng tensorflow_vers on = 5;

    // T  __g _vers on__ str ng of t  tensorflow bu ld used to wr e t 
    // graph. T  w ll be populated by t  fra work, wh ch w ll overwr e any
    // user suppl ed value.
    str ng tensorflow_g _vers on = 6;

    // A flag to denote w t r default-valued attrs have been str pped from
    // t  nodes  n t  graph_def.
    bool str pped_default_attrs = 7;

    // Funct onDef na  to al ases mapp ng.
    map<str ng, str ng> funct on_al ases = 8;
  }
   ta nfoDef  ta_ nfo_def = 1;

  // GraphDef.
  GraphDef graph_def = 2;

  // SaverDef.
  SaverDef saver_def = 3;

  // collect on_def: Map from collect on na  to collect ons.
  // See Collect onDef sect on for deta ls.
  map<str ng, Collect onDef> collect on_def = 4;

  // s gnature_def: Map from user suppl ed key for a s gnature to a s ngle
  // S gnatureDef.
  map<str ng, S gnatureDef> s gnature_def = 5;

  // Asset f le def to be used w h t  def ned graph.
  repeated AssetF leDef asset_f le_def = 6;

  // Extra  nformat on about t  structure of funct ons and stateful objects.
  SavedObjectGraph object_graph_def = 7;
}

// Collect onDef should cover most collect ons.
// To add a user-def ned collect on, do one of t  follow ng:
// 1. For s mple data types, such as str ng,  nt, float:
//      tf.add_to_collect on("y _collect on_na ", y _s mple_value)
//    str ngs w ll be stored as bytes_l st.
//
// 2. For Protobuf types, t re are three ways to add t m:
//    1) tf.add_to_collect on("y _collect on_na ",
//         y _proto.Ser al zeToStr ng())
//
//       collect on_def {
//         key: "user_def ned_bytes_collect on"
//         value {
//           bytes_l st {
//             value: "queue_na : \"test_queue\"\n"
//           }
//         }
//       }
//
//  or
//
//    2) tf.add_to_collect on("y _collect on_na ", str(y _proto))
//
//       collect on_def {
//         key: "user_def ned_str ng_collect on"
//         value {
//          bytes_l st {
//             value: "\n\ntest_queue"
//           }
//         }
//       }
//
//  or
//
//    3) any_buf = any_pb2.Any()
//       tf.add_to_collect on("y _collect on_na ",
//         any_buf.Pack(y _proto))
//
//       collect on_def {
//         key: "user_def ned_any_collect on"
//         value {
//           any_l st {
//             value {
//               type_url: "type.googleap s.com/tensorflow.QueueRunnerDef"
//               value: "\n\ntest_queue"
//             }
//           }
//         }
//       }
//
// 3. For Python objects,  mple nt to_proto() and from_proto(), and reg ster
//    t m  n t  follow ng manner:
//    ops.reg ster_proto_funct on("y _collect on_na ",
//                                proto_type,
//                                to_proto=Y PythonObject.to_proto,
//                                from_proto=Y PythonObject.from_proto)
//    T se funct ons w ll be  nvoked to ser al ze and de-ser al ze t 
//    collect on. For example,
//    ops.reg ster_proto_funct on(ops.GraphKeys.GLOBAL_VAR ABLES,
//                                proto_type=var able_pb2.Var ableDef,
//                                to_proto=Var able.to_proto,
//                                from_proto=Var able.from_proto)
 ssage Collect onDef {
  // NodeL st  s used for collect ng nodes  n graph. For example
  // collect on_def {
  //   key: "summar es"
  //   value {
  //     node_l st {
  //       value: " nput_producer/ScalarSummary:0"
  //       value: "shuffle_batch/ScalarSummary:0"
  //       value: " mageSummary:0"
  //     }
  //   }
   ssage NodeL st {
    repeated str ng value = 1;
  }

  // BytesL st  s used for collect ng str ngs and ser al zed protobufs. For
  // example:
  // collect on_def {
  //   key: "tra nable_var ables"
  //   value {
  //     bytes_l st {
  //       value: "\n\017conv1/  ghts:0\022\024conv1/  ghts/Ass gn
  //              \032\024conv1/  ghts/read:0"
  //       value: "\n\016conv1/b ases:0\022\023conv1/b ases/Ass gn\032
  //              \023conv1/b ases/read:0"
  //     }
  //   }
  // }
   ssage BytesL st {
    repeated bytes value = 1;
  }

  //  nt64L st  s used for collect ng  nt,  nt64 and long values.
   ssage  nt64L st {
    repeated  nt64 value = 1 [packed = true];
  }

  // FloatL st  s used for collect ng float values.
   ssage FloatL st {
    repeated float value = 1 [packed = true];
  }

  // AnyL st  s used for collect ng Any protos.
   ssage AnyL st {
    repeated google.protobuf.Any value = 1;
  }

  oneof k nd {
    NodeL st node_l st = 1;
    BytesL st bytes_l st = 2;
     nt64L st  nt64_l st = 3;
    FloatL st float_l st = 4;
    AnyL st any_l st = 5;
  }
}

//  nformat on about a Tensor necessary for feed ng or retr eval.
 ssage Tensor nfo {
  // For sparse tensors, T  COO encod ng stores a tr ple of values,  nd ces,
  // and shape.
   ssage CooSparse {
    // T  shape of t  values Tensor  s [?].   s dtype must be t  dtype of
    // t  SparseTensor as a whole, g ven  n t  enclos ng Tensor nfo.
    str ng values_tensor_na  = 1;

    // T   nd ces Tensor must have dtype  nt64 and shape [?, ?].
    str ng  nd ces_tensor_na  = 2;

    // T  dynam c log cal shape represented by t  SparseTensor  s recorded  n
    // t  Tensor referenced  re.    must have dtype  nt64 and shape [?].
    str ng dense_shape_tensor_na  = 3;
  }

  // Gener c encod ng for compos e tensors.
   ssage Compos eTensor {
    // T  ser al zed TypeSpec for t  compos e tensor.
    TypeSpecProto type_spec = 1;

    // A Tensor nfo for each flattened component tensor.
    repeated Tensor nfo components = 2;
  }

  oneof encod ng {
    // For dense `Tensor`s, t  na  of t  tensor  n t  graph.
    str ng na  = 1;
    // T re are many poss ble encod ngs of sparse matr ces
    // (https://en.w k ped a.org/w k /Sparse_matr x).  Currently, TensorFlow
    // uses only t  COO encod ng.  T   s supported and docu nted  n t 
    // SparseTensor Python class.
    CooSparse coo_sparse = 4;
    // Gener c encod ng for Compos eTensors.
    Compos eTensor compos e_tensor = 5;
  }
  DataType dtype = 2;
  // T  stat c shape should be recorded  re, to t  extent that   can
  // be known  n advance.   n t  case of a SparseTensor, t  f eld descr bes
  // t  log cal shape of t  represented tensor (aka dense_shape).
  TensorShapeProto tensor_shape = 3;
}

// S gnatureDef def nes t  s gnature of a computat on supported by a TensorFlow
// graph.
//
// For example, a model w h two loss computat ons, shar ng a s ngle  nput,
// m ght have t  follow ng s gnature_def map,  n a  taGraphDef  ssage.
//
// Note that across t  two S gnatureDefs "loss_A" and "loss_B", t   nput key,
// output key, and  thod_na  are  dent cal, and w ll be used by system(s) that
//  mple nt or rely upon t  part cular loss  thod. T  output tensor na s
// d ffer, demonstrat ng how d fferent outputs can ex st for t  sa   thod.
//
// s gnature_def {
//   key: "loss_A"
//   value {
//      nputs {
//       key: " nput"
//       value {
//         na : " nput:0"
//         dtype: DT_STR NG
//         tensor_shape: ...
//       }
//     }
//     outputs {
//       key: "loss_output"
//       value {
//         na : "loss_output_A:0"
//         dtype: DT_FLOAT
//         tensor_shape: ...
//       }
//     }
//      thod_na : "so /package/compute_loss"
//   }
//   ...
// }
// s gnature_def {
//   key: "loss_B"
//   value {
//      nputs {
//       key: " nput"
//       value {
//         na : " nput:0"
//         dtype: DT_STR NG
//         tensor_shape: ...
//       }
//     }
//     outputs {
//       key: "loss_output"
//       value {
//         na : "loss_output_B:0"
//         dtype: DT_FLOAT
//         tensor_shape: ...
//       }
//     }
//      thod_na : "so /package/compute_loss"
//   }
//   ...
// }
 ssage S gnatureDef {
  // Na d  nput para ters.
  map<str ng, Tensor nfo>  nputs = 1;
  // Na d output para ters.
  map<str ng, Tensor nfo> outputs = 2;
  // Extens ble  thod_na   nformat on enabl ng th rd-party users to mark a
  // S gnatureDef as support ng a part cular  thod. T  enables producers and
  // consu rs of S gnatureDefs, e.g. a model def n  on l brary and a serv ng
  // l brary to have a clear hand-off regard ng t  semant cs of a computat on.
  //
  // Note that mult ple S gnatureDefs  n a s ngle  taGraphDef may have t  sa 
  //  thod_na . T   s commonly used to support mult - aded computat on,
  // w re a s ngle graph computat on may return mult ple results.
  str ng  thod_na  = 3;
}

// An asset f le def for a s ngle f le or a set of sharded f les w h t  sa 
// na .
 ssage AssetF leDef {
  // T  tensor to b nd t  asset f lena  to.
  Tensor nfo tensor_ nfo = 1;
  // T  f lena  w h n an assets d rectory. Note: does not  nclude t  path
  // pref x,  .e. d rector es. For an asset at /tmp/path/vocab.txt, t  f lena 
  // would be "vocab.txt".
  str ng f lena  = 2;
}
