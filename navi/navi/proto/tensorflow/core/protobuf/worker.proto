/* Copyr ght 2016 T  TensorFlow Authors. All R ghts Reserved.

L censed under t  Apac  L cense, Vers on 2.0 (t  "L cense");
  may not use t  f le except  n compl ance w h t  L cense.
  may obta n a copy of t  L cense at

    http://www.apac .org/l censes/L CENSE-2.0

Unless requ red by appl cable law or agreed to  n wr  ng, software
d str buted under t  L cense  s d str buted on an "AS  S" BAS S,
W THOUT WARRANT ES OR COND T ONS OF ANY K ND, e  r express or  mpl ed.
See t  L cense for t  spec f c language govern ng perm ss ons and
l m at ons under t  L cense.
==============================================================================*/

syntax = "proto3";

package tensorflow;

 mport "google/protobuf/any.proto";
 mport "tensorflow/core/fra work/cost_graph.proto";
 mport "tensorflow/core/fra work/dev ce_attr butes.proto";
 mport "tensorflow/core/fra work/graph.proto";
 mport "tensorflow/core/fra work/step_stats.proto";
 mport "tensorflow/core/fra work/tensor.proto";
 mport "tensorflow/core/fra work/tensor_shape.proto";
 mport "tensorflow/core/fra work/types.proto";
 mport "tensorflow/core/protobuf/conf g.proto";
 mport "tensorflow/core/protobuf/coord nat on_conf g.proto";
 mport "tensorflow/core/protobuf/debug.proto";
 mport "tensorflow/core/protobuf/error_codes.proto";
 mport "tensorflow/core/protobuf/na d_tensor.proto";
 mport "tensorflow/core/protobuf/tensorflow_server.proto";

opt on cc_enable_arenas = true;
opt on java_outer_classna  = "WorkerProtos";
opt on java_mult ple_f les = true;
opt on java_package = "org.tensorflow.d strunt  ";
opt on go_package = "g hub.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto";

////////////////////////////////////////////////////////////////////////////////
//
// GetStatus  thod request/response  ssages
//
////////////////////////////////////////////////////////////////////////////////

 ssage GetStatusRequest {}

 ssage GetStatusResponse {
  repeated Dev ceAttr butes dev ce_attr butes = 1;
}

////////////////////////////////////////////////////////////////////////////////
//
// CreateSess on  thod request/response  ssages
//
// For each sess on,
//
////////////////////////////////////////////////////////////////////////////////

 ssage CreateWorkerSess onRequest {
  // Sess ons are  dent f ed by a g ven handle.
  str ng sess on_handle = 1;

  // Def nes t  conf gurat on of a TensorFlow worker.
  ServerDef server_def = 2;

  //  f true, any res ces such as Var ables used  n t  sess on w ll not be
  // shared w h ot r sess ons.
  bool  solate_sess on_state = 3;

  // T  dev ce attr butes of all t  dev ces  n t  cluster.
  repeated Dev ceAttr butes cluster_dev ce_attr butes = 4;

  // T  master task na  from wh ch t  request  s sent.
  str ng master_task = 5;

  // T   ncarnat on  D of t  master task local CPU dev ce.
  //  f t  target worker already has a WorkerSess on created prev ously w h
  // t  sa  master task na  but a d fferent  ncarnat on,   usually  nd cates
  // that t  prev ous master fa led before delet ng t  WorkerSess on on t 
  // worker. To prevent  mory leaks, t  worker should garbage collect t  old
  // WorkerSess ons.
   nt64 master_ ncarnat on = 6;

  // Conf gures coord nat on serv ce w h n worker sess ons.
  Coord nat onServ ceConf g coord nat on_serv ce_conf g = 7;
}

 ssage CreateWorkerSess onResponse {}

////////////////////////////////////////////////////////////////////////////////
//
// DeleteSess on  thod request/response  ssages
//
// Deletes all worker-s de state assoc ated w h t  g ven sess on handle.
//
////////////////////////////////////////////////////////////////////////////////

 ssage DeleteWorkerSess onRequest {
  // Sess ons are  dent f ed by a g ven handle.
  str ng sess on_handle = 1;
}

 ssage DeleteWorkerSess onResponse {}

////////////////////////////////////////////////////////////////////////////////
//
// Reg sterGraph  thod request/response  ssages
//
// For each sess on, after t  master placed every node on a dev ce,
//   part  ons t  whole graph  nto many subgraphs. All t  nodes  n
// a subgraph  re  n t  sa  worker, but potent ally on many dev ces
// owned by that worker (e.g. cpu0, plus gpu0, gpu1, ..., gpu7). T 
// master reg sters subgraphs for a worker before runn ng any steps. A
// successful reg strat on returns a graph handle to be used  n latter
// RunGraph requests.
//
////////////////////////////////////////////////////////////////////////////////

 ssage Reg sterGraphRequest {
  // Subgraphs are scoped w h n one sess on.
  str ng sess on_handle = 1;

  // Set to true  f `CreateWorkerSess on` was called for `sess on_handle`.
  bool create_worker_sess on_called = 6;

  // "graph_def" has t  subgraph of nodes for t  worker, w h each node
  // hav ng  s dev ce_na  f lled  n.
  GraphDef graph_def = 2;

  // True  ff t  graph (before part  on ng) conta ns control flow nodes.
  //
  // As of 01/11/2015, t   s no longer set by cl ents.
  bool has_control_flow = 3 [deprecated = true];

  // Conf gurat on opt ons for t  sess on  n wh ch t  graph was created.
  GraphOpt ons graph_opt ons = 4;

  // F eld(s) used by TensorFlow Debugger (tfdbg).
  DebugOpt ons debug_opt ons = 5;

  //  f graph_def conta ns any collect ve ops t  must be a pos  ve
  //  nteger used to coord nate execut on w h ot r graphs.  All
  // graphs  n a d str buted execut on w h t  sa 
  // collect ve_graph_key w ll coord nate to use t  sa  step_ d
  // concurrently so that BufRendezvous entr es w ll make t  correct
  // values access ble.
   nt64 collect ve_graph_key = 7;

  // Conf gProto from t  sess on  n wh ch t  graph was created.
  // Conta ns add  onal para ters beyond graph_opt ons,  nclud ng
  // t  na  of t  requested executor.
  Conf gProto conf g_proto = 8;
}

 ssage Reg sterGraphResponse {
  //  f t  reg strat on succeeds, returns an opaque graph_handle to
  // t  master. T  master calls RunGraph w h graph_handle to
  // compute d fferent steps.
  str ng graph_handle = 1;
}

////////////////////////////////////////////////////////////////////////////////
//
// Dereg sterGraph  thod request/response  ssages
//
// T  master dereg sters t  g ven graph_handle w n t  graph  s no
// longer needed (e.g., t  overall graph  s re-sc duled and nodes
// are re-placed).
//
// T  worker dereg sters a graph_handle automat cally accord ng to on
// a TTL-base pol cy  n case of master restarts.
//
////////////////////////////////////////////////////////////////////////////////

 ssage Dereg sterGraphRequest {
  // T  sess on_handle used w n reg ster ng t  graph.  f sess on_handle  s
  // empty, a s ngle global na space  s used.
  str ng sess on_handle = 2;

  // Set to true  f `CreateWorkerSess on` was called for `sess on_handle`.
  bool create_worker_sess on_called = 3;

  // REQU RED: graph_handle must be returned by a Reg sterGraph call
  // to t  sa  WorkerServ ce.
  str ng graph_handle = 1;
}

 ssage Dereg sterGraphResponse {
  // TODO(mrry): Opt onally add summary stats for t  graph.
}

////////////////////////////////////////////////////////////////////////////////
//
// CleanupAll  thod request/response  ssages
//
////////////////////////////////////////////////////////////////////////////////

 ssage CleanupAllRequest {
  // A l st of conta ner na s.
  //
  //  f 'conta ner'  s not empty, releases res ces  n t  g ven
  // conta ners  n all dev ces.
  //
  //  f 'conta ner'  s empty, releases res ces  n t  default
  // conta ner  n all dev ces.
  repeated str ng conta ner = 1;
}

 ssage CleanupAllResponse {}

////////////////////////////////////////////////////////////////////////////////
//
// RunGraph request / response  ssages
//
// T  worker executes all subgraphs reg stered under graph_handle.
// RunGraph returns after t  execut on f n s s or an error  s
// encountered.
// A sequence of RunGraphRequests w h  s_part al may be sent to RunGraph for
// part al graph execut on.
//
////////////////////////////////////////////////////////////////////////////////

// Opt ons spec f c to t  execut on of a s ngle step.
 ssage ExecutorOpts {
  bool record_costs = 1;
  bool record_t  l ne = 3;
  bool record_part  on_graphs = 4;
  bool report_tensor_allocat ons_upon_oom = 5;
}

 ssage RunGraphRequest {
  // sess on_handle  s t  master-generated un que  d for t  sess on.
  //  f sess on_handle  s non-empty,   must be t  sa  as used w n
  // reg ster ng t  graph.  f    s empty, a s ngle global na space  s used to
  // search for t  graph_handle.
  str ng sess on_handle = 8;

  // Set to true  f `CreateWorkerSess on` was called for `sess on_handle`.
  bool create_worker_sess on_called = 10;

  // REQU RED: graph_handle must be returned by a Reg sterGraph call
  // to t  sa  WorkerServ ce.
  str ng graph_handle = 1;

  // A un que  D to d st ngu sh d fferent runs of t  sa  graph.
  //
  // T  master generates a global un que `step_ d` to d st ngu sh
  // d fferent runs of t  graph computat on. Subgraphs commun cate
  // (e.g., send/recv ops) w h each ot r us ng `step_ d` to
  // d st ngu sh tensors generated by d fferent runs.
   nt64 step_ d = 2;

  // Opt ons for t  step.
  ExecutorOpts exec_opts = 5;

  // Runs t  graph.
  //
  // Sends t  tensors  n "send"  nto t  graph before t  run and
  // fetc s t  keys  nto `RunGraphResponse.recv` after t  run.
  repeated Na dTensorProto send = 3;
  repeated str ng recv_key = 4;

  // True  f t  RunGraphRequest  s a part al run request.
  bool  s_part al = 6;
  // True  f t   s t  last part al run request  n a sequence of requests.
  bool  s_last_part al_run = 7;

  //  f true t n so  errors, e.g., execut on errors that have long
  // error  ssages, may return an OK RunGraphResponse w h t  actual
  // error saved  n t  status_code/status_error_ ssage f elds of t 
  // response body. T   s a workaround s nce t  RPC subsystem may
  // truncate long  tadata  ssages.
  bool store_errors_ n_response_body = 9;

  // Un que  dent f er for t  request. Every RunGraphRequest must have a
  // un que request_ d, and retr ed RunGraphRequests must have t  sa 
  // request_ d.  f request_ d  s zero, retry detect on  s d sabled.
  //
  // Retr ed RunGraphRequests are problemat c because t y may  ssue a
  // RecvTensor that w ll have no correspond ng sender and w ll wa  forever.
  // Workers use request_ ds to reject retr ed RunGraph requests  nstead of
  // wa  ng forever.
   nt64 request_ d = 11;

  // Next: 12
}

 ssage RunGraphResponse {
  // A l st of tensors correspond ng to those requested by
  // `RunGraphRequest.recv_key`.
  repeated Na dTensorProto recv = 1;

  //  f t  request asked for execut on stats, t  cost graph, or t  part  on
  // graphs, t se are returned  re.
  // TODO(suharshs): Package t se  n a Run tadata  nstead.
  StepStats step_stats = 2;
  CostGraphDef cost_graph = 3;
  repeated GraphDef part  on_graph = 4;

  //  f store_errors_ n_response_body  s true  n t  request, t n
  // opt onally t  server may return an OK status for t  RPC and
  // f ll t  true status  nto t  f elds below, to allow for  ssages
  // that are too long to f   n  tadata.
  error.Code status_code = 5;
  str ng status_error_ ssage = 6;
}

////////////////////////////////////////////////////////////////////////////////
//
// CleanupGraph  thod request/response  ssages
//
// After t  master rece ves RunGraph responses from all workers, t 
// master  nstructs every worker to cleanup any rema n ng state of a
// step (e.g. tensors buffered by a `Send` op but not p cked up by
// ot r workers). T  master does not necessar ly need to wa  for
// complet on of CleanupGraph calls.
//
// Workers should cleanup step states automat cally accord ng to a
// TTL-based pol cy  n case of master restarts.
//
////////////////////////////////////////////////////////////////////////////////

 ssage CleanupGraphRequest {
   nt64 step_ d = 1;
}

 ssage CleanupGraphResponse {}

////////////////////////////////////////////////////////////////////////////////
//
// RecvTensor  thod request/response  ssages
//
////////////////////////////////////////////////////////////////////////////////

 ssage RecvTensorRequest {
  // T  step  n wh ch t  tensor w ll be produced.
  //
  // REQU RED: T  must eventually correspond to t  `step_ d` passed
  //  nto a RunGraph call on t  sa  WorkerServ ce.
   nt64 step_ d = 1;

  // A key  dent fy ng t  channel to rece ve tensors from. A RecvTensor request
  // retr eves one tensor from t  channel, but mult ple tensors can be sent and
  // rece ved over t  sa  channel w h mult ple RecvTensor requests. See
  // rendezvous.h for deta ls.
  str ng rendezvous_key = 2;

  //  f true, use an out-of-band DMA  chan sm to transfer t 
  // rece ved tensor.
  bool dma_ok = 3;

  // Opt onal  nformat on on cl ent-s de dev ce local y.
  Dev ceLocal y cl ent_local y = 4;

  // Opt onal  nformat on on server-s de dev ce local y.
  Dev ceLocal y server_local y = 5;

  // Opt onal  nformat on needed by t  RPC subsystem.
  google.protobuf.Any transport_opt ons = 6;

  // Un que  dent f er for t  request. Every RecvTensorRequest must have a
  // un que request_ d, and retr ed RecvTensorRequests must have t  sa 
  // request_ d.  f request_ d  s zero, retry detect on and response cac 
  // are d sabled.
  //
  // Retr ed RecvTensorRequests are problemat c because a RecvTensor w h no
  // correspond ng sender w ll wa  forever, and t  tensor may have been
  // del vered to a prev ous retry. Workers use request_ ds to reject retr ed
  // RecvTensor requests  nstead of wa  ng forever.
   nt64 request_ d = 7;
}

 ssage RecvTensorResponse {
  // T  tensor as a proto.
  TensorProto tensor = 1;

  //  f true, t  tensor was t  output of a dead node, and t 
  // content  s  nval d.
  bool  s_dead = 2;

  // T  t   at wh ch tensor was ava lable and started to be returned.
   nt64 send_start_m cros = 3;

  // Opt onal add  onal  nformat on about how to rece ve t  tensor,
  // e.g.  n t  event that `RecvTensorRequest.dma_ok` was true.
  google.protobuf.Any transport_opt ons = 4;

  // W t r t  rece ver should send a MarkRecvF n s dRequest to t  sender
  // to ack t   ssage.
  bool requ re_ack = 5;
}

//  ssage for manag ng t  response cac  ma nta ned on t  sender s de.
// Currently only used by t  gRPC worker serv ce.
 ssage MarkRecvF n s dRequest {
   nt64 request_ d = 1;
}

 ssage MarkRecvF n s dResponse {}

////////////////////////////////////////////////////////////////////////////////
//
// Logg ng  thod request/response  ssages
//
// NOTE(mrry): T  feature  s not supported  n t  open-s ce
// vers on, and t se  ssages are expected to change.
//
////////////////////////////////////////////////////////////////////////////////

// Out-of-band request to beg n or end logg ng, or
// to retr eve logs for part cular steps.
 ssage Logg ngRequest {
  //  f true, RPC logg ng w ll be enabled.
  bool enable_rpc_logg ng = 1;

  //  f true, RPC logg ng w ll be d sabled.
  bool d sable_rpc_logg ng = 4;

  //  f true, d scard any saved logg ng data (for all steps).
  bool clear = 2;

  // W n set, requests all saved log data perta n ng to t  step.
  // Any log data retr eved  s el m nated from t  store and cannot be
  // retr eved aga n.
  repeated  nt64 fetch_step_ d = 3;
}

 ssage LabeledStepStats {
   nt64 step_ d = 1;
  StepStats step_stats = 2;
}

 ssage Logg ngResponse {
  repeated LabeledStepStats step = 1;
}

////////////////////////////////////////////////////////////////////////////////
//
// Trac ng  thod request/response  ssages
//
// NOTE(mrry): T  feature  s not supported  n t  open-s ce
// vers on, and t se  ssages are expected to change.
//
////////////////////////////////////////////////////////////////////////////////

 ssage TraceOpts {
  // Length of t  trace to be taken,  n seconds.
  double durat on = 1;
  //  f true, capture step prof le locally  n each worker. Currently
  // un mple nted.
  bool use_step_prof ler = 2;
  //  f true, capture kernel events from each worker.
  bool use_kernel_prof ler = 3;
  //  f true, capture extended prof l ng events from TensorFlow process.
  bool use_extended_prof ler = 4;
  //  f true, capture GPU prof l ng events locally on each
  // mach ne. Currently un mple nted.
  bool use_gpu_prof ler = 5;
  //  f true, collect sampled prof le events. Currently un mple nted.
  bool use_sample_prof ler = 6;
}

// Out-of-band request to conf gure d str buted trac ng.
 ssage Trac ngRequest {
  TraceOpts opt ons = 1;
}

 ssage Trac ngResponse {}

////////////////////////////////////////////////////////////////////////////////
//
// Raw data transfers  n support of Collect ve Ops.
// T se  thods are exper  ntal and subject to change.
//
// T   ntent on  s to allow collect ves to take advantage of t  most
// eff c ent  thods ava lable on a platform, e.g. RDMA, and not be
// constra ned to use t  RPC system  n use by ot r  thods.
//
////////////////////////////////////////////////////////////////////////////////

 ssage RecvBufRequest {
  // Use of t  f elds below may vary by  mple ntat on.  For example
  // t  buf_ptr and num_bytes may be set only for local operat ons and
  // not sent on t  w re, or only sent on t  w re  n one d rect on.

  // Used at server s de to f nd t  correct BufRendezvous.
   nt64 step_ d = 1;

  // Arb rary str ng  dent fy ng a BufRendezvous entry.
  str ng buf_rendezvous_key = 2;

  // S ze of value expected, must agree w h BufRendezvous entry.
   nt64 num_bytes = 3;

  // W n RDMA  s  n use, address of dest nat on f eld on cl ent.
  f xed64 buf_ptr = 4;

  // Opt onal  nformat on on cl ent-s de dev ce local y.
  Dev ceLocal y cl ent_local y = 5;

  // Opt onal  nformat on on server-s de dev ce local y.
  Dev ceLocal y server_local y = 6;

  // Opt onal,  mple ntat on-spec f c data.
  google.protobuf.Any transport_opt ons = 7;
  // For annotat ng t  l ne and dev ce  ncarnat on c ck.
  str ng src_dev ce = 8;
  // Opt onal, for annotat ng t  t  l ne.
  str ng dst_dev ce = 9;

  // Depend ng on t  RPC system  n use,   may be necessary to set t 
  //  d to detect resends of RPCs w re t  server  s not aware that
  // t  pr or RPC fa led.
   nt64 request_ d = 10;

  //  ncarnat on number of t  s ce dev ce, used to detect worker fa lures.
  u nt64 src_ ncarnat on = 11;
}

 ssage RecvBufResponse {
  // Use of t  f elds below may vary by  mple ntat on.  Com nts g ve
  //  ntended use.

  f xed64 buf_ptr = 1;  // Address of s ce f eld on server.
   nt64 num_bytes = 2;  // Byte length of buf_ptr f eld,  f set.
  bool  s_dead = 3;     // True  f value  s 'dead' l ke a tensor.
  // Opt onal,  mple ntat on-spec f c data.
  google.protobuf.Any transport_opt ons = 4;
  // Opt onal, for t  l ne.
   nt64 send_start_m cros = 5;

  // W t r t  rece ver should send a MarkRecvF n s dRequest to t  sender
  // to ack t   ssage.
  bool requ re_ack = 6;
}

////////////////////////////////////////////////////////////////////////////////
//
// Collect ve Op dynam c group resolut on  ssages.
//
////////////////////////////////////////////////////////////////////////////////

// Suppl es one or more dev ce na s as  mbers of t  group  dent f ed by
// group_key.  Serv ce w ll respond w n all group_s ze dev ces beco  known.
// All dev ces  n group must have sa  type.
 ssage CompleteGroupRequest {
   nt32 group_key = 1;
   nt32 group_s ze = 2;
  str ng dev ce_type = 3;
   nt32 collect ve_type = 5;
  Dev ceAttr butes dev ce_attr butes = 6;

  reserved 4;
}

// G ves t  complete  mbersh p of t  group  dent f ed by group_key.
 ssage CompleteGroupResponse {
   nt32 group_key = 1;
   nt32 group_s ze = 2;
  str ng dev ce_type = 3;
   nt32 num_tasks = 4;  // number of d st nct tasks host ng t  dev ces
  bytes commun cator_key = 7;
  repeated Dev ceAttr butes dev ce_attr butes = 8;

  reserved 5, 6;
}

// Suppl es data about one collect ve op belong ng to t   nstance  dent f ed
// by  nstance_key.  Serv ce w ll respond w n all group_s ze ops have
// beco  known.  Most of t  data be ng sent  s for correctness c ck ng,
// to ensure that all ops  n t   nstance share common attr butes.
 ssage Complete nstanceRequest {
  str ng na  = 1;
   nt32 type = 2;
  DataType data_type = 3;
  TensorShapeProto shape = 4;
   nt32 group_key = 5;
   nt32 group_s ze = 6;
   nt32  nstance_key = 7;
  str ng dev ce_type = 8;
  repeated  nt32 subd v_offset = 9;
  str ng dev ce = 10;
  bool  s_s ce = 11;
}

// Conf rms that every op  n t   nstance has cons stently declared  self.
// Also g ves t  s ce_rank  n case of broadcast.
 ssage Complete nstanceResponse {
   nt32  nstance_key = 1;
   nt32 s ce_rank = 2;
  reserved 3;
}

// Request for next agreed-upon step_ d for t  spec f ed graph_keys.
// T   s used to enable mult ple graphs conta n ng nodes from
// a common collect ve  nstance to coord nate us ng t  sa  step_ ds.
 ssage GetStepSequenceRequest {
  repeated  nt64 graph_key = 1;
}

 ssage StepSequence {
   nt64 graph_key = 1;
   nt64 next_step_ d = 2;
}

// Next val d step_ ds for one or more graph_keys.
 ssage GetStepSequenceResponse {
  repeated StepSequence step_sequence = 1;
}
