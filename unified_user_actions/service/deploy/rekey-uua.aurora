 mport os
 mport  ertools
 mport subprocess
 mport math

SERV CE_NAME = 'rekey-uua'

CPU_NUM = 3
HEAP_S ZE = 3 * GB
RAM_S ZE = HEAP_S ZE + 1 * GB
#   make d sk s ze larger than HEAP so that  f   ever need to do a  ap dump,   w ll f  on d sk.
D SK_S ZE = HEAP_S ZE + 2 * GB

class Prof le(Struct):
  package = Default(Str ng, SERV CE_NAME)
  cmdl ne_flags = Default(Str ng, '')
  log_level = Default(Str ng, ' NFO')
   nstances = Default( nteger, 100)
  kafka_bootstrap_servers = Default(Str ng, '/s/kafka/blueb rd-1:kafka-tls')
  kafka_bootstrap_servers_remote_dest = Default(Str ng, '/s/kafka/blueb rd-1:kafka-tls')
  s ce_top c = Default(Str ng, 'un f ed_user_act ons')
  s nk_top cs = Default(Str ng, 'uua_keyed')
  dec der_overlay = Default(Str ng, '')

res ces = Res ces(
  cpu = CPU_NUM,
  ram = RAM_S ZE,
  d sk = D SK_S ZE
)

 nstall = Packer. nstall(
  na  = '{{prof le.package}}',
  vers on = Workflows.package_vers on()
)

async_prof ler_ nstall = Packer. nstall(
  na  = 'async-prof ler',
  role = 'csl-perf',
  vers on = 'latest'
)

setup_jaas_conf g = Process(
    na            = 'setup_jaas_conf g',
    cmdl ne        = '''
    mkd r -p jaas_conf g
    echo "KafkaCl ent {
      com.sun.secur y.auth.module.Krb5Log nModule requ red
      pr nc pal=\\"d scode@TW TTER.B Z\\"
      useKeyTab=true
      storeKey=true
      keyTab=\\"/var/l b/tss/keys/fluffy/keytabs/cl ent/d scode.keytab\\"
      doNotPrompt=true;
  };" >> jaas_conf g/jaas.conf
  '''
)

ma n = JVMProcess(
  na  = SERV CE_NAME,
  jvm = Java11(
    ap                     = HEAP_S ZE,
   extra_jvm_flags =
      '-Djava.net.prefer Pv4Stack=true'

      ' -XX:+UseNUMA'
      ' -XX:+Aggress veOpts'
      ' -XX:+PerfD sableShared m' # http://www.evanjones.ca/jvm-mmap-pause.html

      ' -Dlog_level={{prof le.log_level}}'
      ' -Dlog.access.output=access.log'
      ' -Dlog.serv ce.output={{na }}.log'
      ' -Djava.secur y.auth.log n.conf g=jaas_conf g/jaas.conf'
  ),
  argu nts =
    '-jar {{na }}-b n.jar'
    ' -adm n.port=:{{t rmos.ports[ alth]}}'
    ' -kafka.bootstrap.servers={{prof le.kafka_bootstrap_servers}}'
    ' -kafka.bootstrap.servers.remote.dest={{prof le.kafka_bootstrap_servers_remote_dest}}'
    ' -kafka.group. d={{na }}-{{env ron nt}}'
    ' -kafka.producer.cl ent. d={{na }}-{{env ron nt}}'
    ' -kafka.max.pend ng.requests=10000'
    ' -kafka.consu r.fetch.max=1. gabytes'
    ' -kafka.producer.batch.s ze=16.k lobytes'
    ' -kafka.producer.buffer. m=128. gabytes'
    ' -kafka.producer.l nger=50.m ll seconds'
    ' -kafka.producer.request.t  out=30.seconds'
    ' -kafka.producer.compress on.type=lz4'
    ' -kafka.worker.threads=5'
    ' -kafka.s ce.top c={{prof le.s ce_top c}}'
    ' -kafka.s nk.top cs={{prof le.s nk_top cs}}'
    ' -dec der.base=dec der.yml'
    ' -dec der.overlay={{prof le.dec der_overlay}}'
    ' -cluster={{cluster}}'
    ' {{prof le.cmdl ne_flags}}',
  res ces = res ces
)

stats = Stats(
  l brary = ' tr cs',
  port = 'adm n'
)

job_template = Serv ce(
  na  = SERV CE_NAME,
  role = 'd scode',
   nstances = '{{prof le. nstances}}',
  contact = 'd sco-data-eng@tw ter.com',
  constra nts = {'rack': 'l m :1', 'host': 'l m :1'},
  announce = Announcer(
    pr mary_port = ' alth',
    portmap = {'aurora': ' alth', 'adm n': ' alth'}
  ),
  task = Task(
    res ces = res ces,
    na  = SERV CE_NAME,
    processes = [async_prof ler_ nstall,  nstall, setup_jaas_conf g, ma n, stats],
    constra nts = order(async_prof ler_ nstall,  nstall, setup_jaas_conf g, ma n)
  ),
   alth_c ck_conf g         =  althC ckConf g(
     n  al_ nterval_secs     = 100,
     nterval_secs             = 60,
    t  out_secs              = 60,
    max_consecut ve_fa lures  = 4
  ),
  update_conf g               = UpdateConf g(
    batch_s ze                = 100,
    watch_secs                = 90,
    max_per_shard_fa lures    = 3,
    max_total_fa lures        = 0,
    rollback_on_fa lure       = False
  )
)

PRODUCT ON = Prof le(
  # go/uua-dec der
  dec der_overlay = '/usr/local/conf g/overlays/d scode-default/Un f edUserAct ons/prod/{{cluster}}/dec der_overlay.yml'
)

STAG NG = Prof le(
  package = SERV CE_NAME+'-stag ng',
  cmdl ne_flags = '',
  kafka_bootstrap_servers_remote_dest = '/srv#/devel/local/kafka/ ngest on-1:kafka-tls',
  dec der_overlay = '/usr/local/conf g/overlays/d scode-default/Un f edUserAct ons/stag ng/{{cluster}}/dec der_overlay.yml' # go/uua-dec der
)

DEVEL = STAG NG(
  log_level = 'DEBUG',
)


prod_job = job_template(
  t er = 'preferred',
  env ron nt = 'prod',
).b nd(prof le = PRODUCT ON)

stag ng_job = job_template(
  env ron nt = 'stag ng'
).b nd(prof le = STAG NG)

devel_job = job_template(
  env ron nt = 'devel'
).b nd(prof le = DEVEL)

jobs = []
for cluster  n ['atla', 'pdxa']:
  jobs.append(prod_job(cluster = cluster))
  jobs.append(stag ng_job(cluster = cluster))
  jobs.append(devel_job(cluster = cluster))
